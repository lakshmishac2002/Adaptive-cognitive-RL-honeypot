#!/usr/bin/env python3
"""
Comprehensive Test Script
Verifies all 15 issues are fixed before training
"""
import numpy as np
import sys

from honeypot_environment_enhanced import EnhancedHoneypotEnvironment
from custom_rl_agent import FixedHoneypotRLAgent


def test_reward_normalization():
    """Test #2: Rewards should be bounded"""
    print("\n" + "=" * 70)
    print("TEST #2: REWARD NORMALIZATION")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    
    max_reward = -float('inf')
    min_reward = float('inf')
    
    for attack_idx in range(9):
        env.current_attack_type = attack_idx
        state = env.reset()
        
        for _ in range(30):
            action = np.random.randint(0, 6)
            state, reward, done, info = env.step(action)
            max_reward = max(max_reward, reward)
            min_reward = min(min_reward, reward)
            if done:
                break
    
    print(f"  Reward range: [{min_reward:.1f}, {max_reward:.1f}]")
    
    if abs(max_reward) > 200 or abs(min_reward) > 200:
        print("  ‚ùå FAIL: Rewards not normalized (should be ~[-50, 100])")
        return False
    else:
        print("  ‚úÖ PASS: Rewards properly bounded")
        return True


def test_episode_length():
    """Test #7 & #14: Episodes shouldn't max out"""
    print("\n" + "=" * 70)
    print("TEST #7/#14: EPISODE LENGTH & TIME-FARMING")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    
    episode_lengths = []
    
    for _ in range(20):
        state = env.reset()
        done = False
        steps = 0
        
        while not done and steps < 200:
            action = np.random.randint(0, 6)
            state, reward, done, info = env.step(action)
            steps += 1
        
        episode_lengths.append(steps)
    
    avg_length = np.mean(episode_lengths)
    max_length = np.max(episode_lengths)
    
    print(f"  Average episode length: {avg_length:.1f}")
    print(f"  Max episode length: {max_length}")
    print(f"  Environment max_steps: {env.max_steps}")
    
    if max_length > 150:
        print("  ‚ùå FAIL: Episodes too long (time-farming not prevented)")
        return False
    else:
        print("  ‚úÖ PASS: Episode length reasonable")
        return True


def test_block_incentive():
    """Test #4: Block action should be useful"""
    print("\n" + "=" * 70)
    print("TEST #4: BLOCK ACTION INCENTIVIZED")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    
    # Test DDoS with block
    env.current_attack_type = 4  # ddos
    state = env.reset()
    
    # Gather some intelligence first
    for _ in range(10):
        state, _, _, _ = env.step(3)  # fake_data
    
    # Now block
    state, block_reward, done, info = env.step(5)  # block
    
    print(f"  DDoS + Block reward: {block_reward:.1f}")
    print(f"  Intelligence gathered: {info['intelligence']}")
    
    if block_reward > 0:
        print("  ‚úÖ PASS: Block action has positive reward for DDoS")
        return True
    else:
        print("  ‚ùå FAIL: Block action not incentivized")
        return False


def test_state_differentiation():
    """Test #15: Different attacks should have different states"""
    print("\n" + "=" * 70)
    print("TEST #15: STATE DIFFERENTIATION")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    
    states = {}
    for attack_idx in range(9):
        env.current_attack_type = attack_idx
        state = env.reset()
        attack_name = env.attack_types[attack_idx]
        states[attack_name] = state
    
    # Check if states are different
    unique_states = set()
    for attack, state in states.items():
        # Use first 9 elements (one-hot encoding)
        state_sig = tuple(state[:9])
        unique_states.add(state_sig)
    
    print(f"  Unique state signatures: {len(unique_states)}/9")
    
    if len(unique_states) == 9:
        print("  ‚úÖ PASS: Each attack has unique state encoding")
        return True
    else:
        print("  ‚ùå FAIL: Attacks not properly differentiated")
        return False


def test_action_penalties():
    """Test #6: Bad actions should be penalized"""
    print("\n" + "=" * 70)
    print("TEST #6: BAD ACTION PENALTIES")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    
    # Test XSS with respond_realistic (bad action)
    env.current_attack_type = 3  # xss
    state = env.reset()
    
    # Try bad action
    state, bad_reward, _, _ = env.step(0)  # respond_realistic
    
    # Reset and try good action
    state = env.reset()
    state, good_reward, _, _ = env.step(3)  # fake_data
    
    print(f"  XSS + respond_realistic: {bad_reward:.1f}")
    print(f"  XSS + fake_data: {good_reward:.1f}")
    
    if good_reward > bad_reward:
        print("  ‚úÖ PASS: Bad actions penalized vs good actions")
        return True
    else:
        print("  ‚ùå FAIL: Bad actions not properly penalized")
        return False


def test_strict_success_criteria():
    """Test #3: Success criteria should be strict"""
    print("\n" + "=" * 70)
    print("TEST #3: STRICT SUCCESS CRITERIA")
    print("=" * 70)
    
    # Simulate episodes with different outcomes
    test_cases = [
        {'engaged': 15, 'intel': 20, 'stealth': 0.5, 'steps': 40, 'expected': True},
        {'engaged': 15, 'intel': 20, 'stealth': 0.8, 'steps': 40, 'expected': False},  # Bad stealth
        {'engaged': 5, 'intel': 20, 'stealth': 0.5, 'steps': 40, 'expected': False},   # Low engagement
        {'engaged': 15, 'intel': 5, 'stealth': 0.5, 'steps': 40, 'expected': False},   # Low intel
        {'engaged': 15, 'intel': 20, 'stealth': 0.5, 'steps': 80, 'expected': False},  # Time-farming
    ]
    
    passed = 0
    for i, case in enumerate(test_cases):
        criteria = {
            'good_engagement': case['engaged'] >= 10,
            'intelligence_gathered': case['intel'] >= 15,
            'stealth_maintained': case['stealth'] < 0.6,
            'not_time_farming': case['steps'] <= 60
        }
        is_success = all(criteria.values())
        
        if is_success == case['expected']:
            passed += 1
            status = "‚úì"
        else:
            status = "‚úó"
        
        print(f"  Case {i+1}: {status} {'SUCCESS' if is_success else 'FAIL'} "
              f"(expected {'SUCCESS' if case['expected'] else 'FAIL'})")
    
    if passed == len(test_cases):
        print("  ‚úÖ PASS: Success criteria working correctly")
        return True
    else:
        print(f"  ‚ùå FAIL: Only {passed}/{len(test_cases)} cases correct")
        return False


def test_eval_diversity_mechanism():
    """Test #1 & #5: Evaluation should maintain diversity"""
    print("\n" + "=" * 70)
    print("TEST #1/#5: EVALUATION DIVERSITY MECHANISM")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    agent = FixedHoneypotRLAgent(env.state_dim, env.action_dim)
    
    # Simulate evaluation (training=False)
    agent.reset_eval_counts()
    
    for _ in range(100):
        state = env.reset()
        action = agent.select_action(state, training=False)
    
    # Check distribution
    action_counts = agent.eval_action_counts
    percentages = (action_counts / action_counts.sum()) * 100
    max_usage = np.max(percentages)
    
    print(f"  Evaluation action distribution:")
    for i, pct in enumerate(percentages):
        print(f"    Action {i}: {pct:.1f}%")
    
    print(f"  Max action usage: {max_usage:.1f}%")
    
    if max_usage > 80:
        print("  ‚ùå FAIL: Evaluation diversity collapsed")
        return False
    else:
        print("  ‚úÖ PASS: Evaluation maintains diversity")
        return True


def test_q_value_normalization():
    """Test #11: Q-values should be normalized"""
    print("\n" + "=" * 70)
    print("TEST #11: Q-VALUE NORMALIZATION")
    print("=" * 70)
    
    env = EnhancedHoneypotEnvironment()
    agent = FixedHoneypotRLAgent(env.state_dim, env.action_dim)
    
    # Get Q-values for random state
    state = env.reset()
    
    import torch
    with torch.no_grad():
        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(agent.device)
        q_values = agent.policy_net(state_tensor).cpu().numpy()[0]
    
    print(f"  Q-value range: [{np.min(q_values):.1f}, {np.max(q_values):.1f}]")
    
    if np.max(np.abs(q_values)) > 200:
        print("  ‚ùå FAIL: Q-values not normalized (too large)")
        return False
    else:
        print("  ‚úÖ PASS: Q-values in reasonable range")
        return True


def run_all_tests():
    """Run all tests"""
    print("\n" + "=" * 70)
    print("COMPREHENSIVE TEST SUITE - ALL 15 FIXES")
    print("=" * 70)
    
    tests = [
        ("Reward Normalization (#2)", test_reward_normalization),
        ("Episode Length & Time-Farming (#7, #14)", test_episode_length),
        ("Block Action Incentive (#4)", test_block_incentive),
        ("State Differentiation (#15)", test_state_differentiation),
        ("Bad Action Penalties (#6)", test_action_penalties),
        ("Strict Success Criteria (#3)", test_strict_success_criteria),
        ("Evaluation Diversity (#1, #5)", test_eval_diversity_mechanism),
        ("Q-Value Normalization (#11)", test_q_value_normalization),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n  ‚ùå ERROR in {test_name}: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {test_name:50s}: {status}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nüéâ ALL TESTS PASSED! Ready to train!")
        return True
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed. Review fixes before training.")
        return False


if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("COMPREHENSIVE FIX VALIDATION")
    print("Testing all 15 issue fixes...")
    print("=" * 70)
    
    success = run_all_tests()
    
    if success:
        print("\n" + "=" * 70)
        print("‚úÖ VALIDATION COMPLETE - ALL SYSTEMS GO!")
        print("=" * 70)
        print("\nRun training:")
        print("  python train_final_fixed.py --episodes 500")
        print("\nExpected results:")
        print("  ‚Ä¢ Rewards in [-50, 100] range")
        print("  ‚Ä¢ Episode lengths 30-60 steps")
        print("  ‚Ä¢ Evaluation diversity 70-80%")
        print("  ‚Ä¢ Success rate 60-75%")
        print("  ‚Ä¢ Block action used 10-15%")
        print("=" * 70)
        sys.exit(0)
    else:
        print("\n" + "=" * 70)
        print("‚ùå VALIDATION FAILED")
        print("=" * 70)
        print("\nSome fixes need adjustment. Review test output above.")
        sys.exit(1)
